---
title: "The Beauty of Reticulate"
author: "Ryan Bailey"
date: '2020-12-08'


thumbnail: "featured.jpg"
image:
  caption: 'Photo by Romina Farías  on Unsplash'
  placement: 3
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
---



<p>Python and R are integral to data science, period. There is no way around using them. Each language is great in its own right, but together, they’re unstoppable. In the below notebook, I am training a scikit-learn Support Vector Machine (SVM) classifier on <a href="https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set">Diabetic Retinopathy Debrecen Dataset</a>. If you’re unfamiliar with SVMs, I highly recommend <a href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47">this article by Rohith Gandhi</a> from the Towards Data Science blog on Medium. After we build the classifier, I do some hyperparameter tuning until I reach a reasonable accuracy.</p>
<p>All this stuff can be done in Python easily. But I want to use ggplot to visualize the dataset. Reticulate lets R and Python communicate with each others’ environment. After I finish the classifier, I reduced the dimensionality of the dataset via UMAP. At the very bottom of the notebook, I show how the SVM’s <code>predict</code> functionality is preserved from Python to R.</p>
<div id="load-in-the-reticulate-library" class="section level2">
<h2>Load in the Reticulate library</h2>
<pre class="r"><code>library(reticulate)</code></pre>
</div>
<div id="check-the-python-configuration-to-make-sure-the-paths-and-versions-look-good" class="section level2">
<h2>Check the Python configuration to make sure the paths and versions look good</h2>
<pre class="r"><code>py_config()</code></pre>
<pre><code>## python:         /Users/ryanbailey/Library/r-miniconda/envs/r-reticulate/bin/python
## libpython:      /Users/ryanbailey/Library/r-miniconda/envs/r-reticulate/lib/libpython3.6m.dylib
## pythonhome:     /Users/ryanbailey/Library/r-miniconda/envs/r-reticulate:/Users/ryanbailey/Library/r-miniconda/envs/r-reticulate
## version:        3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:19:23)  [GCC Clang 10.0.1 ]
## numpy:          /Users/ryanbailey/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/numpy
## numpy_version:  1.19.4</code></pre>
</div>
<div id="importing-packages" class="section level2">
<h2>Importing Packages</h2>
<pre class="python"><code>#!/usr/bin/env python
# coding: utf-8

#You may add additional imports
import warnings
warnings.simplefilter(&quot;ignore&quot;)
import pandas as pd
import numpy as np
import sklearn as sk
import matplotlib.pyplot as plt
import time
from sklearn.model_selection import GridSearchCV as GSCV
from sklearn.model_selection import cross_val_score</code></pre>
<p>##Load in the dataset (Diabetic Retinopathy Debrecen Data Set)</p>
<pre class="python"><code>col_names = []
for i in range(20):
    if i == 0:
        col_names.append(&#39;quality&#39;)
    if i == 1:
        col_names.append(&#39;prescreen&#39;)
    if i &gt;= 2 and i &lt;= 7:
        col_names.append(&#39;ma&#39; + str(i))
    if i &gt;= 8 and i &lt;= 15:
        col_names.append(&#39;exudate&#39; + str(i))
    if i == 16:
        col_names.append(&#39;euDist&#39;)
    if i == 17:
        col_names.append(&#39;diameter&#39;)
    if i == 18:
        col_names.append(&#39;amfm_class&#39;)
    if i == 19:
        col_names.append(&#39;label&#39;)

data = pd.read_csv(&quot;messidor_features.txt&quot;, names = col_names)
print(data.shape)</code></pre>
<pre><code>## (1151, 20)</code></pre>
<pre class="python"><code>data.head(10)</code></pre>
<pre><code>##    quality  prescreen  ma2  ma3  ...    euDist  diameter  amfm_class  label
## 0        1          1   22   22  ...  0.486903  0.100025           1      0
## 1        1          1   24   24  ...  0.520908  0.144414           0      0
## 2        1          1   62   60  ...  0.530904  0.128548           0      1
## 3        1          1   55   53  ...  0.483284  0.114790           0      0
## 4        1          1   44   44  ...  0.475935  0.123572           0      1
## 5        1          1   44   43  ...  0.502831  0.126741           0      1
## 6        1          0   29   29  ...  0.541743  0.139575           0      1
## 7        1          1    6    6  ...  0.576318  0.071071           1      0
## 8        1          1   22   21  ...  0.500073  0.116793           0      1
## 9        1          1   79   75  ...  0.560959  0.109134           0      1
## 
## [10 rows x 20 columns]</code></pre>
<pre class="python"><code>datay = data[&#39;label&#39;]
datax = data.drop(&#39;label&#39;,axis =1 )
print(datay.shape)</code></pre>
<pre><code>## (1151,)</code></pre>
<pre class="python"><code>print(datax.shape)</code></pre>
<pre><code>## (1151, 19)</code></pre>
<pre class="python"><code>datax.head()</code></pre>
<pre><code>##    quality  prescreen  ma2  ma3  ...  exudate15    euDist  diameter  amfm_class
## 0        1          1   22   22  ...   0.003923  0.486903  0.100025           1
## 1        1          1   24   24  ...   0.003903  0.520908  0.144414           0
## 2        1          1   62   60  ...   0.007744  0.530904  0.128548           0
## 3        1          1   55   53  ...   0.001531  0.483284  0.114790           0
## 4        1          1   44   44  ...   0.000000  0.475935  0.123572           0
## 
## [5 rows x 19 columns]</code></pre>
</div>
<div id="building-a-pipeline-to-first-scale-the-data-then-to-train-the-model" class="section level2">
<h2>Building a pipeline to first scale the data, then to train the model</h2>
<pre class="python"><code>from sklearn.preprocessing import StandardScaler as SS
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
SS = SS()
clf = SVC()
pipe = Pipeline(steps=[(&#39;scaler&#39;, SS), (&#39;SVC&#39;, clf)])

nested_score = cross_val_score(pipe, datax, datay, cv=5)
print(&#39;Mean Nested Score:&#39;,nested_score.mean())</code></pre>
<pre><code>## Mean Nested Score: 0.7011368341803125</code></pre>
</div>
<div id="hyperparameter-tuning" class="section level2">
<h2>Hyperparameter Tuning</h2>
<pre class="python"><code># for the &#39;svm&#39; part of the pipeline, tune the &#39;kernel&#39; hyperparameter
param_grid = {&#39;SVC__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;, &#39;sigmoid&#39;]}
grid_search = GSCV(pipe, param_grid, cv=5, scoring=&#39;accuracy&#39;)
grid_search.fit(datax,datay)</code></pre>
<pre><code>## GridSearchCV(cv=5,
##              estimator=Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
##                                        (&#39;SVC&#39;, SVC())]),
##              param_grid={&#39;SVC__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;, &#39;sigmoid&#39;]},
##              scoring=&#39;accuracy&#39;)</code></pre>
<pre class="python"><code>best_kernel = grid_search.best_params_.get(&#39;SVC__kernel&#39;)
print(grid_search.best_params_)</code></pre>
<pre><code>## {&#39;SVC__kernel&#39;: &#39;linear&#39;}</code></pre>
<pre class="python"><code>print(&quot;Accuracy:&quot;, grid_search.best_score_)</code></pre>
<pre><code>## Accuracy: 0.7228646715603239</code></pre>
</div>
<div id="nested-cross-validation-mean-accuracy" class="section level2">
<h2>Nested cross validation mean accuracy</h2>
<pre class="python"><code>nested_score = cross_val_score(grid_search, datax, datay, cv=5)
print(&#39;Mean Nested Score: &#39;,nested_score.mean())</code></pre>
<pre><code>## Mean Nested Score:  0.7228646715603239</code></pre>
</div>
<div id="cross-validating-the-hyperparameter-tuned-model" class="section level2">
<h2>Cross Validating the Hyperparameter-tuned Model</h2>
<pre class="python"><code>param_grid = {&#39;SVC__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;, &#39;sigmoid&#39;],&#39;SVC__C&#39;:list(range(50,110,10))}
grid_search = GSCV(pipe, param_grid, cv=5, scoring=&#39;accuracy&#39;)
grid_search.fit(datax,datay)</code></pre>
<pre><code>## GridSearchCV(cv=5,
##              estimator=Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
##                                        (&#39;SVC&#39;, SVC())]),
##              param_grid={&#39;SVC__C&#39;: [50, 60, 70, 80, 90, 100],
##                          &#39;SVC__kernel&#39;: [&#39;linear&#39;, &#39;rbf&#39;, &#39;poly&#39;, &#39;sigmoid&#39;]},
##              scoring=&#39;accuracy&#39;)</code></pre>
<pre class="python"><code>best_kernel = grid_search.best_params_.get(&#39;SVC__kernel&#39;)
print(grid_search.best_params_)</code></pre>
<pre><code>## {&#39;SVC__C&#39;: 70, &#39;SVC__kernel&#39;: &#39;linear&#39;}</code></pre>
<pre class="python"><code>print(&quot;Accuracy:&quot;, grid_search.best_score_)</code></pre>
<pre><code>## Accuracy: 0.7463052889139845</code></pre>
<pre class="python"><code>nested_score = cross_val_score(grid_search, datax, datay, cv=5)
print(&#39;Mean Nested Score:&#39;,nested_score.mean())
</code></pre>
<pre><code>## Mean Nested Score: 0.7454357236965933</code></pre>
</div>
<div id="loading-in-r-packages" class="section level2">
<h2>Loading in R packages</h2>
<pre class="r"><code>library(umap)</code></pre>
<pre><code>## Warning: package &#39;umap&#39; was built under R version 3.6.2</code></pre>
<pre class="r"><code>library(readr)
library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ──────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.3.1     ✓ dplyr   1.0.0
## ✓ tibble  3.0.1     ✓ stringr 1.4.0
## ✓ tidyr   1.1.0     ✓ forcats 0.5.0
## ✓ purrr   0.3.4</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;purrr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.6.2</code></pre>
<pre><code>## ── Conflicts ─────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(ggplot2)
library(ggalt)</code></pre>
<pre><code>## Registered S3 methods overwritten by &#39;ggalt&#39;:
##   method                  from   
##   grid.draw.absoluteGrob  ggplot2
##   grobHeight.absoluteGrob ggplot2
##   grobWidth.absoluteGrob  ggplot2
##   grobX.absoluteGrob      ggplot2
##   grobY.absoluteGrob      ggplot2</code></pre>
<pre class="r"><code>library(ggforce)</code></pre>
<pre><code>## Warning: package &#39;ggforce&#39; was built under R version 3.6.2</code></pre>
<pre class="r"><code>library(concaveman)</code></pre>
<pre><code>## Warning: package &#39;concaveman&#39; was built under R version 3.6.2</code></pre>
</div>
<div id="collapsing-the-data-with-umap" class="section level1">
<h1>Collapsing the data with UMAP</h1>
<pre class="r"><code>set.seed(3)
labels &lt;- py$data %&gt;% pull(label)
data &lt;- py$data %&gt;% select(-label)
data_umap = umap(data)
umap_features &lt;- cbind(((data_umap$layout) %&gt;% as.data.frame),labels) %&gt;% 
  mutate(label = as.factor(labels)) %&gt;% 
  select(-labels)
umap_features %&gt;% head</code></pre>
<pre><code>##           V1        V2 label
## 1 -1.5948603  2.517664     0
## 2 -1.2361083  2.352496     0
## 3  0.8065302 -2.698501     1
## 4 -0.1869378 -3.680573     0
## 5 -3.2231895 -3.336815     1
## 6 -2.6021497 -2.833544     1</code></pre>
<div id="plot-the-umap-data" class="section level4">
<h4>Plot the UMAP Data</h4>
<pre class="r"><code>umap_features %&gt;% 
  ggplot(aes(x = V1, y =V2, color = as.factor(labels))) + 
  geom_point(size = 3) + theme_minimal() + 
  geom_mark_ellipse(expand = 0,aes(fill=as.factor(labels))) +
  xlab(&quot;UMAP Feature 1&quot;) + 
  ylab(&quot;UMAP Feature 2&quot;)</code></pre>
<p><img src="/post/Reticulate/index_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="extracting-the-predict-method-from-the-svm" class="section level2">
<h2>Extracting the predict method from the SVM</h2>
<pre class="r"><code>predict &lt;- py$grid_search$predict
set.seed(1)
predict(data[sample(1:nrow(data),2),])</code></pre>
<pre><code>## [1] 0 1</code></pre>
</div>
</div>
